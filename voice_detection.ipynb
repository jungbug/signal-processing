{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 301)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "[['1.00', '0.00']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:57:25.577680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "import scipy.signal\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('voice_recognition_model.h5')\n",
    "\n",
    "y, sr = librosa.load(\"./generated_noise_0.wav\")\n",
    "\n",
    "hop_length = int(sr * 0.010)  # 프레임 크기 (여기서는 10ms)\n",
    "n_fft = int(sr * 0.025)  # FFT 크기 (여기서는 25ms)\n",
    "spectrogram = np.abs(librosa.stft(y, hop_length=hop_length, n_fft=n_fft))\n",
    "print(spectrogram.shape)\n",
    "prediction = model.predict(spectrogram.reshape(1, 276, 301, 1))\n",
    "prediction = [[format(num, '.2f') for num in sublist] for sublist in prediction]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(200, 276, 301, 1)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# .wav 파일이 저장된 폴더\n",
    "folder_path = './testset/'\n",
    "\n",
    "# .wav 파일을 스펙트로그램으로 변환하여 저장할 리스트\n",
    "spectrograms = []\n",
    "labels = []\n",
    "\n",
    "# '0'과 '1' 폴더를 순회\n",
    "for label in ['0', '1']:\n",
    "    label_folder_path = os.path.join(folder_path, label)\n",
    "    print(label)\n",
    "\n",
    "    # folder_path 내의 모든 파일을 순회\n",
    "    for file_name in os.listdir(label_folder_path):\n",
    "        # .wav 파일만 처리\n",
    "        if file_name.endswith('.wav'):\n",
    "            # 오디오 파일 읽기\n",
    "            y, sr = librosa.load(os.path.join(label_folder_path, file_name))\n",
    "\n",
    "            hop_length = int(sr * 0.010)  # 프레임 크기 (여기서는 10ms)\n",
    "            n_fft = int(sr * 0.025)  # FFT 크기 (여기서는 25ms)\n",
    "            spectrogram = np.abs(librosa.stft(y, hop_length=hop_length, n_fft=n_fft))\n",
    "\n",
    "            # # 오디오 파일을 스펙트로그램으로 변환\n",
    "            # D = librosa.stft(y)\n",
    "            # spectrogram = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "\n",
    "            # 리스트에 스펙트로그램 추가\n",
    "            spectrograms.append(spectrogram)\n",
    "\n",
    "            # 레이블 추가\n",
    "            labels.append(int(label))\n",
    "\n",
    "# numpy 배열로 변환\n",
    "X_test = np.array(spectrograms)\n",
    "Y_test = np.array(labels)\n",
    "\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 50ms/step - loss: 1.4281e-04 - accuracy: 1.0000\n",
      "[0.00014281136100180447, 1.0]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 18:26:23.800725: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "결과: 인식 됨\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "결과: 인식 안됨\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "결과: 인식 안됨\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "\n",
    "# 모델 불러오기\n",
    "model = tf.keras.models.load_model('voice_recognition_model.h5')\n",
    "\n",
    "arrayList = []\n",
    "# 오디오 스트림 콜백 함수\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    indata = indata[0:201]\n",
    "    # arrayList에 indata 추가\n",
    "    arrayList.append(indata)\n",
    "    if len(arrayList) == 301:\n",
    "        arr = np.array(arrayList).transpose()\n",
    "    # 예측\n",
    "        prediction = model.predict(arr)\n",
    "        prediction = [[format(num, '.2f') for num in sublist] for sublist in prediction]\n",
    "    # 결과 출력\n",
    "        answer = [\"인식 안됨\", \"인식 됨\"]\n",
    "        print('결과:', answer[np.argmax(prediction)])\n",
    "        arrayList.clear()\n",
    "    # print('인식 결과:', prediction)\n",
    "\n",
    "# 오디오 스트림 시작\n",
    "stream = sd.InputStream(callback=audio_callback, channels=1, samplerate=43000)\n",
    "stream.start()\n",
    "\n",
    "# 입력 대기\n",
    "input('목소리 인식 중... (끝내려면 Enter 키를 누르세요)')\n",
    "\n",
    "# 오디오 스트림 종료\n",
    "stream.stop()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 60501 into shape (1,276,301,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(librosa\u001b[38;5;241m.\u001b[39mstft(y, hop_length\u001b[38;5;241m=\u001b[39mhop_length, n_fft\u001b[38;5;241m=\u001b[39mn_fft))\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoice_recognition_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mspectrogram\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m276\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m301\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m prediction \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;28mformat\u001b[39m(num, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m sublist] \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m prediction]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 60501 into shape (1,276,301,1)"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(os.path.join(\"./test_output.wav\"), sr=16000)\n",
    "print(y.shape)\n",
    "\n",
    "hop_length = int(sr * 0.010)  # 프레임 크기 (여기서는 10ms)\n",
    "n_fft = int(sr * 0.025)  # FFT 크기 (여기서는 25ms)\n",
    "spectrogram = np.abs(librosa.stft(y, hop_length=hop_length, n_fft=n_fft))\n",
    "\n",
    "model = tf.keras.models.load_model('voice_recognition_model.h5')\n",
    "\n",
    "prediction = model.predict(spectrogram.reshape(1, 276, 301, 1))\n",
    "prediction = [[format(num, '.2f') for num in sublist] for sublist in prediction]\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal_tensorflow_mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
